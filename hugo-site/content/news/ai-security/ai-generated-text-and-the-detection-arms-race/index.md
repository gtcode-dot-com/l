---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: ai-security
date: '2026-02-14T20:06:32.690928+00:00'
exported_at: '2026-02-14T20:06:35.749142+00:00'
feed: https://www.schneier.com/feed/atom/
language: en
source_url: https://www.schneier.com/blog/archives/2026/02/the-ai-generated-text-arms-race.html
structured_data:
  about: []
  author: ''
  description: In 2023, the science fiction literary magazine Clarkesworld stopped
    accepting new submissions because so many were generated by artificial intelligence.
    Near as the editors could tell, many submitters pasted the magazine’s detailed
    story guidelines into an AI and sent in the results. And they weren’t alone. Other
    fiction magazines have also reported a high number of AI-generated submissions.
    This is only one example of a ubiquitous trend. A legacy system relied on the
    difficulty of writing and cognition to limit volume. Generative AI overwhelms
    the system because the humans on the receiving end can’t keep up...
  headline: AI-Generated Text and the Detection Arms Race
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: https://www.schneier.com/blog/archives/2026/02/the-ai-generated-text-arms-race.html
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: AI-Generated Text and the Detection Arms Race
updated_at: '2026-02-14T20:06:32.690928+00:00'
url_hash: c34eedb359b2e13a00b64a082c3ff01536940a88
---

## AI-Generated Text and the Detection Arms Race

In 2023, the science fiction literary magazine
Clarkesworld
[stopped accepting](https://www.npr.org/2023/02/24/1159286436/ai-chatbot-chatgpt-magazine-clarkesworld-artificial-intelligence)
new submissions because so many were generated by artificial intelligence. Near as the editors could tell, many submitters pasted the magazine’s detailed story guidelines into an AI and sent in the results. And they weren’t alone. Other fiction magazines have also
[reported a high number](https://www.theverge.com/2023/2/25/23613752/ai-generated-short-stories-literary-magazines-clarkesworld-science-fiction)
of AI-generated submissions.

This is only one example of a ubiquitous trend. A legacy system relied on the difficulty of writing and cognition to limit volume. Generative AI overwhelms the system because the humans on the receiving end can’t keep up.

This is happening everywhere. Newspapers are being inundated by AI-generated
[letters to the editor](https://www.nytimes.com/2025/11/04/science/letters-to-the-editor-ai-chatbots.html)
, as are
[academic journals](https://www.marketplace.org/episode/2025/11/24/ai-generated-letters-to-the-editor-are-flooding-academic-publications)
. Lawmakers are inundated with AI-generated
[constituent comments](https://government.cornell.edu/news/lawmakers-struggle-differentiate-ai-and-human-emails)
. Courts around the world are flooded with AI-generated
[filings](https://www.law.com/international-edition/2025/11/25/courts-being-flooded-by-wordy-ai-generated-documents-report-finds/)
, particularly by people representing themselves. AI conferences are
[flooded](https://futurism.com/artificial-intelligence/ai-research-papers-slop)
with AI-generated research papers. Social media
[is](https://www.app.com/story/news/2025/12/07/how-to-deal-with-fake-ai-stories-popping-up-on-facebook-social-media/87629867007/)
[flooded](https://www.nytimes.com/2025/12/08/technology/ai-slop-sora-social-media.html)
with
[AI posts](https://www.cyberlink.com/blog/photo-marketing-business/3828/best-ai-social-media-post-generator)
. In
[music](https://time.com/7338205/rage-against-ai-generated-music/)
,
[open source software](https://github.com/orgs/community/discussions/159749)
,
[education](https://www.newyorker.com/magazine/2025/07/07/the-end-of-the-english-paper)
,
[investigative journalism](https://bsky.app/profile/eliothiggins.bsky.social/post/3m5yh2gjlj22b)
and
[hiring](https://www.nytimes.com/2025/06/21/business/dealbook/ai-job-applications.html)
, it’s the same story.

Like
Clarkesworld
’s initial response, some of these institutions shut down their submissions processes. Others have met the offensive of AI inputs with some defensive response, often involving a counteracting use of AI. Academic
[peer reviewers](https://doi.org/10.1038/d41586-025-03506-6)
increasingly use AI to evaluate papers that may have been generated by AI. Social media platforms turn to
[AI moderators](https://www.integrityinstitute.org/blog/how-generative-ai-makes-content-moderation-both-harder-and-easier)
. Court systems use AI to
[triage and process](https://restofworld.org/2025/brazil-ai-courts-lawsuits/)
litigation volumes supercharged by AI. Employers turn to
[AI tools](https://www.forbes.com/sites/mariagraciasantillanalinares/2025/12/16/job-applicant-fraud-is-rising-this-startup-is-using-ai-to-stop-it/)
to review candidate applications. Educators use AI not just to
[grade papers](https://www.cnn.com/2024/04/06/tech/teachers-grading-ai)
and
[administer exams](https://www.behind-the-enemy-lines.com/2025/12/fighting-fire-with-fire-scalable-oral.html)
, but as a
[feedback](https://wacclearinghouse.org/repository/collections/textgened/rhetorical-engagements/using-llms-as-peer-reviewers-for-revising-essays/)
tool for students.

These are all arms races: rapid, adversarial iteration to apply a common technology to opposing purposes. Many of these arms races have clearly deleterious effects. Society suffers if the courts are clogged with frivolous, AI-manufactured cases. There is also harm if the established measures of academic performance – publications and citations – accrue to those researchers most willing to fraudulently submit AI-written letters and papers rather than to those whose ideas have the most impact. The fear is that, in the end, fraudulent behavior enabled by AI will undermine systems and institutions that society relies on.

### Upsides of AI

Yet some of these AI arms races have surprising hidden upsides, and the hope is that at least some institutions will be able to change in ways that make them stronger.

Science seems likely to become stronger thanks to AI, yet it faces a problem when the AI makes mistakes. Consider the example of
[nonsensical](https://theconversation.com/a-weird-phrase-is-plaguing-scientific-papers-and-we-traced-it-back-to-a-glitch-in-ai-training-data-254463)
, AI-generated phrasing filtering into scientific papers.

A scientist using an AI to assist in writing an academic paper can be a good thing, if used carefully and with disclosure. AI is increasingly a
[primary tool](https://www.nature.com/articles/s43588-025-00890-x)
in scientific research: for reviewing literature, programming and for coding and analyzing data. And for many, it has become a crucial support for expression and scientific communication. Pre-AI, better-funded researchers could hire humans to help them write their academic papers. For many authors whose primary language is not English, hiring this kind of assistance has been an expensive
[necessity](https://doi.org/10.1098/rspb.2023.2840)
. AI provides it to everyone.

In fiction, fraudulently submitted AI-generated works cause harm, both to the human authors now subject to increased competition and to those readers who may feel defrauded after unknowingly reading the work of a machine. But some outlets may welcome AI-assisted submissions with appropriate disclosure and under particular guidelines, and leverage AI to evaluate them against criteria like originality, fit and quality.

Others may refuse AI-generated work, but this will come at a cost. It’s unlikely that any human editor or technology can sustain an ability to differentiate human from machine writing. Instead, outlets that wish to exclusively publish humans will need to limit submissions to a set of authors they trust to not use AI. If these policies are transparent, readers can pick the format they prefer and read happily from either or both types of outlets.

We also don’t see any problem if a job seeker uses AI to polish their resumes or write better cover letters: The wealthy and privileged have long had access to human assistance for those things. But it crosses the line when AIs are used to
[lie](https://www.cbsnews.com/news/fake-job-seekers-flooding-market-artificial-intelligence/)
about identity and experience, or to
[cheat](https://www.theatlantic.com/technology/2025/10/ai-cheating-job-interviews-fraud/684568/)
on job interviews.

Similarly, a democracy requires that its citizens be able to express their opinions to their representatives, or to each other through a medium like the newspaper. The rich and powerful have long been able to hire writers to turn their ideas into persuasive prose, and AIs providing that assistance to more people is a good thing, in our view. Here, AI mistakes and bias can be harmful. Citizens may be using AI for more than just a time-saving shortcut; it may be augmenting their knowledge and capabilities, generating statements about historical, legal or policy factors they can’t reasonably be expected to independently check.

### Fraud booster

What we don’t want is for lobbyists to use AIs in astroturf campaigns, writing multiple letters and passing them off as individual opinions. This, too, is an
[older problem](https://www.washingtonpost.com/politics/2021/05/14/millions-fake-commenters-asked-fcc-end-net-neutrality-astroturfing-is-business-model/)
that AIs are making worse.

What differentiates the positive from the negative here is not any inherent aspect of the technology, it’s the power dynamic. The same technology that reduces the effort required for a citizen to share their lived experience with their legislator also enables corporate interests to misrepresent the public at scale. The former is a power-equalizing application of AI that enhances participatory democracy; the latter is a power-concentrating application that threatens it.

In general, we believe writing and cognitive assistance, long available to the rich and powerful, should be available to everyone. The problem comes when AIs make fraud easier. Any response needs to balance embracing that newfound democratization of access with preventing fraud.

There’s no way to turn this technology off. Highly capable AIs are widely available and can run on a laptop. Ethical guidelines and clear professional boundaries can help – for those acting in good faith. But there won’t ever be a way to totally stop academic writers, job seekers or citizens from using these tools, either as legitimate assistance or to commit fraud. This means more comments, more letters, more applications, more submissions.

The problem is that whoever is on the receiving end of this AI-fueled deluge can’t deal with the increased volume. What can help is developing assistive AI tools that benefit institutions and society, while also limiting fraud. And that may mean embracing the use of AI assistance in these adversarial systems, even though the defensive AI will never achieve supremacy.

### Balancing harms with benefits

The science fiction community has been wrestling with AI since 2023.
Clarkesworld
eventually reopened submissions,
[claiming](https://www.postalley.org/2024/06/04/the-big-sort-how-will-ai-affect-submissions-to-magazines/)
that it has an adequate way of separating human- and AI-written stories. No one knows how long, or how well, that will continue to work.

The arms race continues. There is no simple way to tell whether the potential benefits of AI will outweigh the harms, now or in the future. But as a society, we can influence the balance of harms it wreaks and opportunities it presents as we muddle our way through the changing technological landscape.

[*This essay was written with Nathan E. Sanders, and originally appeared in The Conversation.*](https://theconversation.com/ai-generated-text-is-overwhelming-institutions-setting-off-a-no-win-arms-race-with-ai-detectors-274720)

EDITED TO ADD: This essay has been translated into
[Spanish](https://www.elconfidencial.com/tecnologia/novaceno/2026-02-07/ia-derriba-sociedad-educacion-legal-medios_4298791/)
.

Tags:
[AI](https://www.schneier.com/tag/ai/)
,
[LLM](https://www.schneier.com/tag/llm/)

[Posted on February 10, 2026 at 7:03 AM](https://www.schneier.com/blog/archives/2026/02/the-ai-generated-text-arms-race.html)
•
[19 Comments](https://www.schneier.com/blog/archives/2026/02/the-ai-generated-text-arms-race.html#comments)