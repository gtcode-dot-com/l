---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: ai-security
date: '2025-12-11T00:03:08.459453+00:00'
exported_at: '2025-12-11T00:03:10.797316+00:00'
feed: https://www.schneier.com/feed/atom/
language: en
source_url: https://www.schneier.com/blog/archives/2025/12/fbi-warns-of-fake-video-scams.html
structured_data:
  about: []
  author: ''
  description: 'The FBI is warning of AI-assisted fake kidnapping scams: Criminal
    actors typically will contact their victims through text message claiming they
    have kidnapped their loved one and demand a ransom be paid for their release.
    Oftentimes, the criminal actor will express significant claims of violence towards
    the loved one if the ransom is not paid immediately. The criminal actor will then
    send what appears to be a genuine photo or video of the victim’s loved one, which
    upon close inspection often reveals inaccuracies when compared to confirmed photos
    of the loved one. Examples of these inaccuracies include missing tattoos or scars
    and inaccurate body proportions. Criminal actors will sometimes purposefully send
    these photos using timed message features to limit the amount of time victims
    have to analyze the images...'
  headline: FBI Warns of Fake Video Scams
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: https://www.schneier.com/blog/archives/2025/12/fbi-warns-of-fake-video-scams.html
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: FBI Warns of Fake Video Scams
updated_at: '2025-12-11T00:03:08.459453+00:00'
url_hash: b83d06e0ded006a015b5c7c4a47e411b2f7fecd4
---

## FBI Warns of Fake Video Scams

The FBI is
[warning](https://www.ic3.gov/PSA/2025/PSA251205)
of AI-assisted fake kidnapping scams:

> Criminal actors typically will contact their victims through text message claiming they have kidnapped their loved one and demand a ransom be paid for their release. Oftentimes, the criminal actor will express significant claims of violence towards the loved one if the ransom is not paid immediately. The criminal actor will then send what appears to be a genuine photo or video of the victim’s loved one, which upon close inspection often reveals inaccuracies when compared to confirmed photos of the loved one. Examples of these inaccuracies include missing tattoos or scars and inaccurate body proportions. Criminal actors will sometimes purposefully send these photos using timed message features to limit the amount of time victims have to analyze the images.

Images, videos, audio: It can all be faked with AI. My guess is that this scam has a low probability of success, so criminals will be figuring out how to automate it.

Tags:
[AI](https://www.schneier.com/tag/ai/)
,
[deepfake](https://www.schneier.com/tag/deepfake/)
,
[FBI](https://www.schneier.com/tag/fbi/)
,
[kidnapping](https://www.schneier.com/tag/kidnapping/)
,
[scams](https://www.schneier.com/tag/scams/)

[Posted on December 10, 2025 at 7:05 AM](https://www.schneier.com/blog/archives/2025/12/fbi-warns-of-fake-video-scams.html)
•
[5 Comments](https://www.schneier.com/blog/archives/2025/12/fbi-warns-of-fake-video-scams.html#comments)

Sidebar photo of Bruce Schneier by Joe MacInnis.