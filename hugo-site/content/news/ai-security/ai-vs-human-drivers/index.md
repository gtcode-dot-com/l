---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: ai-security
date: '2025-12-10T12:03:07.243782+00:00'
exported_at: '2025-12-10T12:03:10.744868+00:00'
feed: https://www.schneier.com/feed/atom/
language: en
source_url: https://www.schneier.com/blog/archives/2025/12/ai-vs-human-drivers.html
structured_data:
  about: []
  author: ''
  description: 'Two competing arguments are making the rounds. The first is by a neurosurgeon
    in the New York Times. In an op-ed that honestly sounds like it was paid for by
    Waymo, the author calls driverless cars a “public health breakthrough”: In medical
    research, there’s a practice of ending a study early when the results are too
    striking to ignore. We stop when there is unexpected harm. We also stop for overwhelming
    benefit, when a treatment is working so well that it would be unethical to continue
    giving anyone a placebo. When an intervention works this clearly, you change what
    you do...'
  headline: AI vs. Human Drivers
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: https://www.schneier.com/blog/archives/2025/12/ai-vs-human-drivers.html
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: AI vs. Human Drivers
updated_at: '2025-12-10T12:03:07.243782+00:00'
url_hash: 820d20f885e8c00fca247d80d3fad60759147c84
---

## AI vs. Human Drivers

Two competing arguments are making the rounds. The first is by a neurosurgeon in the
*New York Times*
. In
[an op-ed](https://archive.is/YDBDz)
that honestly sounds like it was paid for by Waymo, the author calls driverless cars a “public health breakthrough”:

> In medical research, there’s a practice of ending a study early when the results are too striking to ignore. We stop when there is unexpected harm. We also stop for overwhelming benefit, when a treatment is working so well that it would be unethical to continue giving anyone a placebo. When an intervention works this clearly, you change what you do.
>
> There’s a public health imperative to quickly expand the adoption of autonomous vehicles. More than
> [39,000 Americans died](https://www.nhtsa.gov/press-releases/nhtsa-estimates-39345-traffic-fatalities-2024)
> in motor vehicle crashes last year, more than homicide, plane crashes and natural disasters combined. Crashes are the No. 2 cause of death for children and young adults. But death is only part of the story. These crashes are also the leading cause of spinal cord injury. We surgeons see the aftermath of the 10,000 crash victims who come to emergency rooms every day.

The other is a soon-to-be-published book:
*[Driving Intelligence: The Green Book](https://www.amazon.com/Driving-Intelligence-Green-Routes-Autonomy/dp/1032911220)*
. The authors, a computer scientist and a management consultant with experience in the industry, make the opposite argument. Here’s one of the authors:

> There is something very disturbing going on around trials with autonomous vehicles worldwide, where, sadly, there have now been many deaths and injuries both to other road users and pedestrians. Although I am well aware that there is not,
> *senso stricto*
> , a legal and functional parallel between a “drug trial” and “AV testing,” it seems odd to me that if a trial of a new drug had resulted in so many deaths, it would surely have been halted and major forensic investigations carried out and yet, AV manufacturers continue to test their products on public roads unabated.
>
> I am not convinced that it is good enough to argue from statistics that, to a greater or lesser degree, fatalities and injuries would have occurred anyway had the AVs had been replaced by human-driven cars: a pharmaceutical company, following death or injury, cannot simply sidestep regulations around the trial of, say, a new cancer drug, by arguing that, whilst the trial is underway, people would die from cancer anyway….

Both arguments are compelling, and it’s going to be hard to figure out what public policy should be.

This paper, from 2016, argues that we’re going to need other metrics than side-by-side comparisons:
[Driving to safety: How many miles of driving would it take to demonstrate autonomous vehicle reliability?](https://www.sciencedirect.com/science/article/abs/pii/S0965856416302129)
“:

> **Abstract**
> : How safe are autonomous vehicles? The answer is critical for determining how autonomous vehicles may shape motor vehicle safety and public health, and for developing sound policies to govern their deployment. One proposed way to assess safety is to test drive autonomous vehicles in real traffic, observe their performance, and make statistical comparisons to human driver performance. This approach is logical, but it is practical? In this paper, we calculate the number of miles of driving that would be needed to provide clear statistical evidence of autonomous vehicle safety. Given that current traffic fatalities and injuries are rare events compared to vehicle miles traveled, we show that fully autonomous vehicles would have to be driven hundreds of millions of miles and sometimes hundreds of billions of miles to demonstrate their reliability in terms of fatalities and injuries. Under even aggressive testing assumptions, existing fleets would take tens and sometimes hundreds of years to drive these miles—­an impossible proposition if the aim is to demonstrate their performance prior to releasing them on the roads for consumer use. These findings demonstrate that developers of this technology and third-party testers cannot simply drive their way to safety. Instead, they will need to develop innovative methods of demonstrating safety and reliability. And yet, the possibility remains that it will not be possible to establish with certainty the safety of autonomous vehicles. Uncertainty will remain. Therefore, it is imperative that autonomous vehicle regulations are adaptive­—designed from the outset to evolve with the technology so that society can better harness the benefits and manage the risks of these rapidly evolving and potentially transformative technologies.

One problem, of course, is that we treat death by human driver differently than we do death by autonomous computer driver. This is likely to change as we get more experience with AI accidents—and AI-caused deaths.

Tags:
[academic papers](https://www.schneier.com/tag/academic-papers/)
,
[AI](https://www.schneier.com/tag/ai/)
,
[cars](https://www.schneier.com/tag/cars/)

[Posted on December 9, 2025 at 7:07 AM](https://www.schneier.com/blog/archives/2025/12/ai-vs-human-drivers.html)
•
[26 Comments](https://www.schneier.com/blog/archives/2025/12/ai-vs-human-drivers.html#comments)