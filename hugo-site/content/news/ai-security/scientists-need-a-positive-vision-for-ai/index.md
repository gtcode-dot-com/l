---
ai_commentary:
- body: The piece outlines risks including misinformation via AI, deepfakes, enhanced
    warfare capabilities, labor issues for data workers, and substantial energy demands,
    arguing for a more hopeful, proactive framing of AI's role.
  title: Key concerns highlighted
- body: Advocates reframing AI development around ethical use, transparency, inclusive
    governance, and sustainability, alongside sustained, diverse investment in science
    to balance AI priorities.
  title: Toward a positive vision
- body: Recommend responsible science funding, fair compensation for data workers,
    energy-efficient AI models, and regulatory measures that curb abuse while preserving
    innovation and public trust.
  title: Policy and practice suggestions
ai_commentary_meta:
  content_digest: 0a1e1e3926f7f6c783faeb7ecddd3401baba05ba
  generated_at: '2025-11-10T02:03:15.211941+00:00'
  model: gpt-5-nano-2025-08-07
  prompt_version: v2025-11-09
  provider: openai
category: ai-security
date: '2025-11-09T05:30:09.760586+00:00'
exported_at: '2025-11-09T05:31:58.083683+00:00'
feed: https://www.schneier.com/feed/atom/
source_url: https://www.schneier.com/blog/archives/2025/11/scientists-need-a-positive-vision-for-ai.html
structured_data:
  about: &id001
  - Artificial intelligence
  - AI misinformation and deepfakes
  - AI in warfare and societal effects
  - Energy consumption of AI systems
  - Labor practices in AI data labeling
  - Public investment in science and AI policy
  - Big Tech and control of the AI ecosystem
  description: An analysis urging the research community to maintain optimism about
    AI while acknowledging risks such as misinformation, deepfakes, labor practices,
    energy use, and policy shifts, and advocating for a constructive, future-focused
    framework for AI development.
  headline: Scientists Need a Positive Vision for AI
  keywords: *id001
title: Scientists Need a Positive Vision for AI
updated_at: '2025-11-09T05:30:09.760586+00:00'
url_hash: e6716afdd224d4e34ece8978e96094802c01f073
---

## Scientists Need a Positive Vision for AI

For many in the research community, it’s gotten harder to be optimistic about the impacts of
[artificial intelligence](https://spectrum.ieee.org/topic/artificial-intelligence/)
.

As authoritarianism is rising around the world, AI-generated “slop” is overwhelming legitimate media, while AI-generated
[deepfakes](https://spectrum.ieee.org/tag/deepfakes)
are spreading
[misinformation](https://spectrum.ieee.org/tag/misinformation)
and parroting extremist messages. AI is making warfare more precise and deadly amidst intransigent conflicts. AI companies are exploiting people in the global South who work as data labelers, and profiting from content creators worldwide by using their work without license or compensation. The industry is also affecting an already-roiling climate with its
[enormous energy demands](https://spectrum.ieee.org/ai-energy-use)
.

Meanwhile, particularly in the
[United States](https://spectrum.ieee.org/tag/united-states)
, public investment in science seems to be
[redirected](https://www.aau.edu/newsroom/leading-research-universities-report/white-house-proposes-steep-cuts-science-and-education)
and
[concentrated](https://www.aip.org/fyi/trump-plan-highlights-ai-for-science)
on AI at the expense of other disciplines. And
[Big Tech](https://spectrum.ieee.org/tag/big-tech)
companies are consolidating their control over the AI ecosystem. In these ways and others, AI seems to be making everything worse.

This is not the whole story. We should not resign ourselves to AI being harmful to humanity. None of us should accept this as inevitable, especially those in a position to influence science, government, and society. Scientists and engineers can push AI towards a beneficial path. Here’s how.

### The Academy’s View of AI

A
[Pew study](https://www.pewresearch.org/internet/2025/04/03/how-the-us-public-and-ai-experts-view-artificial-intelligence/)
in April found that 56 percent of AI experts (authors and presenters of AI-related conference papers) predict that AI will have positive effects on society. But that optimism doesn’t extend to the scientific community at large. A 2023
[survey](https://sci-ops.org/survey/artificial-intelligence-survey-x/scientists-perceptions-and-personal-use/)
of 232 scientists by the Center for Science, Technology and
[Environmental Policy](https://spectrum.ieee.org/tag/environmental-policy)
Studies at Arizona State University found more concern than excitement about the use of
[generative AI](https://spectrum.ieee.org/tag/generative-ai)
in daily life—by nearly a three to one ratio.

We have encountered this sentiment repeatedly. Our careers of diverse applied work have brought us in contact with many research communities: privacy,
[cybersecurity](https://spectrum.ieee.org/tag/cybersecurity)
, physical sciences,
[drug discovery](https://spectrum.ieee.org/tag/drug-discovery)
,
[public health](https://spectrum.ieee.org/tag/public-health)
, public interest technology, and democratic innovation. In all of these fields, we’ve found strong negative sentiment about the impacts of AI. The feeling is so palpable that we’ve often been asked to represent the voice of the AI optimist, even though we spend most of our time writing about the need to reform the structures of AI development.

We understand why these audiences see AI as a destructive force, but this negativity engenders a different concern: that those with the potential to guide the development of AI and steer its influence on society will view it as a lost cause and sit out that process.

### Elements of a Positive Vision for AI

[Many](https://www.islandinstitute.org/working-waterfront/hope-a-framework-for-climate-action/)
[have](https://time.com/7178677/climate-scientist-optimist-refuse-to-give-up-hope/)
[a](https://www.nature.com/articles/s41467-018-05977-w)
[rgu](https://www.nature.com/articles/s41467-018-05977-w)
[ed](https://www.nature.com/articles/s41467-018-05977-w)
[that](https://behavioralscientist.org/we-need-to-change-the-way-we-talk-about-climate-change/)
[turn](https://www.forbes.com/sites/avivahwittenbergcox/2023/04/17/the-power-of-climate-optimists-flip-the-narrative-change-the-future/)
[ing](https://www.forbes.com/sites/avivahwittenbergcox/2023/04/17/the-power-of-climate-optimists-flip-the-narrative-change-the-future/)
the
[tide](https://climate.mit.edu/podcasts/making-case-climate-optimism)
of climate action requires clearly articulating a path towards positive outcomes. In the same way, while scientists and technologists should anticipate, warn against, and help mitigate the potential harms of AI, they should also highlight the ways the technology can be harnessed for good, galvanizing public action towards those ends.

There are myriad ways to leverage and reshape AI to improve peoples’ lives, distribute rather than concentrate power, and even strengthen democratic processes. Many examples have arisen from the scientific community and deserve to be celebrated.

Some examples: AI is eliminating communication barriers across languages, including under-resourced contexts like
[marginalized sign languages](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5230744)
and
[indigenous African languages](https://ojs.bilpub.com/index.php/card/article/view/517)
. It is helping policymakers incorporate the viewpoints of many constituents through AI-assisted
[deliberations](https://www.science.org/doi/abs/10.1126/science.adq2852)
and
[legislative engagement](https://static.ie.edu/CGC/AI4D%20Paper%203%20Applications%20of%20Artificial%20Intelligence%20Tools%20to%20Engance%20Legislative%20Engagement.pdf)
.
[Large language models](https://spectrum.ieee.org/tag/large-language-models)
can scale individual dialogs to
[a](https://osf.io/mqcwj_v1/)
[ddress](https://osf.io/mqcwj_v1/)
[climate](https://osf.io/mqcwj_v1/)
[–](https://osf.io/mqcwj_v1/)
[change skepticism](https://osf.io/mqcwj_v1/)
, spreading accurate information at a critical moment. National labs are building AI
[foundation models](https://www.anl.gov/cels/auroragpt-foundation-models-for-science)
to accelerate scientific research. And throughout the fields of medicine and biology,
[machine learning](https://spectrum.ieee.org/tag/machine-learning)
is solving scientific problems like the prediction of protein structure in aid of drug discovery, which was recognized with a
[Nobel Prize](https://www.nobelprize.org/prizes/chemistry/2024/press-release/)
in 2024.

While each of these applications is nascent and surely imperfect, they all demonstrate that AI can be wielded to advance the public interest. Scientists should embrace, champion, and expand on such efforts.

### A Call to Action for Scientists

In our new book,
*[Rewiring Democracy: How AI Will Transform Our Politics, Government, and Citizenship](https://mitpress.mit.edu/9780262049948/rewiring-democracy/)*
, we describe four key actions for policymakers committed to steering AI toward the public good.

These apply to scientists as well. Researchers should work to
**reform**
the AI industry to be more ethical, equitable, and trustworthy. We must collectively
[develop](https://www.unesco.org/en/legal-affairs/recommendation-ethics-artificial-intelligence)
[ethical](https://www.pnas.org/doi/10.1073/pnas.2407886121)
[norms](https://link.springer.com/article/10.1007/s43681-024-00493-8)
for research that advance and applies AI, and should use and draw attention to AI developers who adhere to those norms.

Second, we should
**resist**
harmful uses of AI by documenting the negative applications of AI and casting a light on inappropriate uses.

Third, we should
**responsibly use**
AI to make society and peoples’ lives better, exploiting its capabilities to help the communities they serve.

And finally, we must advocate for the
**renovation**
of institutions to prepare them for the impacts of AI; universities, professional societies, and democratic organizations are all vulnerable to disruption.

Scientists have a special privilege and responsibility: We are close to the technology itself and therefore well positioned to influence its trajectory. We must work to create an AI-infused world that we want to live in. Technology, as the historian
[Melvin Kranzberg observed](https://www.jstor.org/stable/3105385)
, “is neither good nor bad; nor is it neutral.” Whether the AI we build is detrimental or beneficial to society depends on the choices we make today. But we cannot create a positive future without a vision of what it looks like.

*This essay was written with Nathan E. Sanders, and originally appeared in
[IEEE Spectrum](https://spectrum.ieee.org/responsible-ai)
.*

Tags:
[AI](https://www.schneier.com/tag/ai/)
,
[LLM](https://www.schneier.com/tag/llm/)

[Posted on November 5, 2025 at 7:04 AM](https://www.schneier.com/blog/archives/2025/11/scientists-need-a-positive-vision-for-ai.html)
•
[11 Comments](https://www.schneier.com/blog/archives/2025/11/scientists-need-a-positive-vision-for-ai.html#comments)