---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: ai-security
date: '2026-01-08T21:46:19.322061+00:00'
exported_at: '2026-01-08T21:46:22.603488+00:00'
feed: https://feeds.feedburner.com/TheHackersNews
language: en
source_url: https://thehackernews.com/2026/01/openai-launches-chatgpt-health-with.html
structured_data:
  about: []
  author: ''
  description: OpenAI introduces ChatGPT Health, a separate, encrypted space for health
    chats with optional app data access, focused on privacy and support—not diagn
  headline: OpenAI Launches ChatGPT Health with Isolated, Encrypted Health Data Controls
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: https://thehackernews.com/2026/01/openai-launches-chatgpt-health-with.html
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: OpenAI Launches ChatGPT Health with Isolated, Encrypted Health Data Controls
updated_at: '2026-01-08T21:46:19.322061+00:00'
url_hash: a5e359c7625fcc1cf87a7bdb4dc4b642ccc53d65
---

**

Jan 08, 2026
**

Ravie Lakshmanan

Privacy / Artificial Intelligence

Artificial intelligence (AI) company OpenAI on Wednesday announced the launch of ChatGPT Health, a dedicated space that allows users to have conversations with the chatbot about their health.

To that end, the sandboxed experience offers users the optional ability to securely connect medical records and wellness apps, including Apple Health, Function, MyFitnessPal, Weight Watchers, AllTrails, Instacart, and Peloton, to get tailored responses, lab test insights, nutrition advice, personalized meal ideas, and suggested workout classes.

The new feature is rolling out for users with ChatGPT Free, Go, Plus, and Pro plans outside of the European Economic Area, Switzerland, and the U.K.

"ChatGPT Health builds on the strong privacy, security, and data controls across ChatGPT with additional, layered protections designed specifically for health -- including purpose-built encryption and isolation to keep health conversations protected and compartmentalized," OpenAI
[said](https://openai.com/index/introducing-chatgpt-health/)
in a statement.

Stating that over 230 million people globally ask health and wellness-related questions on the platform every week, OpenAI emphasized that the tool is designed to support medical care, not replace it or be used as a substitute for diagnosis or treatment.

The company also highlighted the various privacy and security features built into the Health experience -

* Health operates in silo with enhanced privacy and its own memory to safeguard sensitive data using "purpose-built" encryption and isolation
* Conversations in Health are not used to train OpenAI's foundation models
* Users who attempt to have a health-related conversation in ChatGPT are prompted to switch over to Health for additional protections
* Health information and memories is not used to contextualize non-Health chats
* Conversations outside of Health cannot access files, conversations, or memories created within Health
* Apps can only connect with users' health data with their explicit permission, even if they're already connected to ChatGPT for conversations outside of Health
* All apps available in Health are required to meet OpenAI's privacy and security requirements, such as collecting only the minimum data needed, and undergo additional security review for them to be included in Health

Furthermore, OpenAI pointed out that it has evaluated the model that powers Health against clinical standards using
[HealthBench⁠](https://openai.com/index/healthbench/)
, a benchmark the company revealed in May 2025 as a way to better measure the capabilities of AI systems for health, putting safety, clarity, and escalation of care in focus.

"This evaluation-driven approach helps ensure the model performs well on the tasks people actually need help with, including explaining lab results in accessible language, preparing questions for an appointment, interpreting data from wearables and wellness apps, and summarizing care instructions," it added.

OpenAI's announcement follows an investigation from The Guardian that
[found](https://www.theguardian.com/technology/2026/jan/02/google-ai-overviews-risk-harm-misleading-health-information)
Google AI Overviews to be providing false and misleading health information. OpenAI and Character.AI are also
[facing several lawsuits](https://apnews.com/article/openai-chatgpt-lawsuit-suicide-56e63e5538602ea39116f1904bf7cdc3)
claiming
[their tools](https://edition.cnn.com/2026/01/07/business/character-ai-google-settle-teen-suicide-lawsuit)
drove people to suicide and harmful delusions after confiding in them. A report
[published](https://www.sfgate.com/tech/article/calif-teen-chatgpt-drug-advice-fatal-overdose-21266718.php)
by SFGate earlier this week detailed how a 19-year-old died of a drug overdose after trusting ChatGPT for medical advice.