---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: ai-security
date: '2026-02-12T20:15:16.799955+00:00'
exported_at: '2026-02-12T20:15:19.940411+00:00'
feed: https://www.schneier.com/feed/atom/
language: en
source_url: https://www.schneier.com/blog/archives/2026/02/prompt-injection-via-road-signs.html
structured_data:
  about: []
  author: ''
  description: 'Interesting research: “CHAI: Command Hijacking Against Embodied AI.”
    Abstract: Embodied Artificial Intelligence (AI) promises to handle edge cases
    in robotic vehicle systems where data is scarce by using common-sense reasoning
    grounded in perception and action to generalize beyond training distributions
    and adapt to novel real-world situations. These capabilities, however, also create
    new security risks. In this paper, we introduce CHAI (Command Hijacking against
    embodied AI), a new class of prompt-based attacks that exploit the multimodal
    language interpretation abilities of Large Visual-Language Models (LVLMs). CHAI
    embeds deceptive natural language instructions, such as misleading signs, in visual
    input, systematically searches the token space, builds a dictionary of prompts,
    and guides an attacker model to generate Visual Attack Prompts. We evaluate CHAI
    on four LVLM agents; drone emergency landing, autonomous driving, and aerial object
    tracking, and on a real robotic vehicle. Our experiments show that CHAI consistently
    outperforms state-of-the-art attacks. By exploiting the semantic and multimodal
    reasoning strengths of next-generation embodied AI systems, CHAI underscores the
    urgent need for defenses that extend beyond traditional adversarial robustness...'
  headline: Prompt Injection Via Road Signs
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: https://www.schneier.com/blog/archives/2026/02/prompt-injection-via-road-signs.html
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: Prompt Injection Via Road Signs
updated_at: '2026-02-12T20:15:16.799955+00:00'
url_hash: 026ec793d8b674a33708fbf09074e37830a8a333
---

## Prompt Injection Via Road Signs

Interesting research: “
[CHAI: Command Hijacking Against Embodied AI](https://arxiv.org/pdf/2510.00181)
.”

> **Abstract:**
> Embodied Artificial Intelligence (AI) promises to handle edge cases in robotic vehicle systems where data is scarce by using common-sense reasoning grounded in perception and action to generalize beyond training distributions and adapt to novel real-world situations. These capabilities, however, also create new security risks. In this paper, we introduce CHAI (Command Hijacking against embodied AI), a new class of prompt-based attacks that exploit the multimodal language interpretation abilities of Large Visual-Language Models (LVLMs). CHAI embeds deceptive natural language instructions, such as misleading signs, in visual input, systematically searches the token space, builds a dictionary of prompts, and guides an attacker model to generate Visual Attack Prompts. We evaluate CHAI on four LVLM agents; drone emergency landing, autonomous driving, and aerial object tracking, and on a real robotic vehicle. Our experiments show that CHAI consistently outperforms state-of-the-art attacks. By exploiting the semantic and multimodal reasoning strengths of next-generation embodied AI systems, CHAI underscores the urgent need for defenses that extend beyond traditional adversarial robustness.

News
[article](https://www.theregister.com/2026/01/30/road_sign_hijack_ai/)
.

Tags:
[academic papers](https://www.schneier.com/tag/academic-papers/)
,
[AI](https://www.schneier.com/tag/ai/)
,
[cars](https://www.schneier.com/tag/cars/)
,
[hacking](https://www.schneier.com/tag/hacking/)

[Posted on February 11, 2026 at 7:03 AM](https://www.schneier.com/blog/archives/2026/02/prompt-injection-via-road-signs.html)
•
[7 Comments](https://www.schneier.com/blog/archives/2026/02/prompt-injection-via-road-signs.html#comments)

Sidebar photo of Bruce Schneier by Joe MacInnis.