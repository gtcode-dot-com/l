---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: ai-security
date: '2026-01-13T16:15:15.170420+00:00'
exported_at: '2026-01-13T16:15:17.456637+00:00'
feed: https://feeds.feedburner.com/TheHackersNews
language: en
source_url: https://thehackernews.com/2026/01/webinar-t-from-mcps-and-tool-access-to.html
structured_data:
  about: []
  author: ''
  description: AI agents now build and run software automatically. Insecure MCPs and
    CVE-2025-6514 show how trusted automation enables code execution attacks.
  headline: '[Webinar] Securing Agentic AI: From MCPs and Tool Access to Shadow API
    Key Sprawl'
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: https://thehackernews.com/2026/01/webinar-t-from-mcps-and-tool-access-to.html
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: '[Webinar] Securing Agentic AI: From MCPs and Tool Access to Shadow API Key
  Sprawl'
updated_at: '2026-01-13T16:15:15.170420+00:00'
url_hash: da274c948bd6e0495113dfc5c14194304953f190
---

**

Jan 13, 2026
**

The Hacker News

Artificial Intelligence / Automation Security

AI agents are no longer just writing code. They are executing it.

Tools like Copilot, Claude Code, and Codex can now build, test, and deploy software end-to-end in minutes. That speed is reshaping engineering—but it's also creating a security gap most teams don't see until something breaks.

Behind every agentic workflow sits a layer few organizations are actively securing:
**[Machine Control Protocols](https://thehacker.news/securing-agentic-ai?source=article)
(MCPs)**
. These systems quietly decide what an AI agent can run, which tools it can call, which APIs it can access, and what infrastructure it can touch. Once that control plane is compromised or misconfigured, the agent doesn't just make mistakes—it acts with authority.

Ask the teams impacted by
**CVE-2025-6514**
. One flaw turned a trusted OAuth proxy used by more than 500,000 developers into a remote code execution path. No exotic exploit chain. No noisy breach. Just automation doing exactly what it was allowed to do—at scale. That incident made one thing clear: if an AI agent can execute commands, it can also execute attacks.

[This webinar is for teams](https://thehacker.news/securing-agentic-ai?source=article)
who want to move fast
**without**
giving up control.

[Secure your spot for the live session ➜](https://thehacker.news/securing-agentic-ai?source=article)

Led by the author of the OpenID whitepaper
*Identity Management for Agentic AI*
, this session goes straight to the core risks security teams are now inheriting from agentic AI adoption. You'll see how MCP servers actually work in real environments, where shadow API keys appear, how permissions quietly sprawl, and why traditional identity and access models break down when agents act on your behalf.

**You'll learn:**

* What MCP servers are and why they matter more than the model itself
* How malicious or compromised MCPs turn automation into an attack surface
* Where shadow API keys come from—and how to detect and eliminate them
* How to audit agent actions and enforce policy before deployment
* Practical controls to secure agentic AI without slowing development

Agentic AI is already inside your pipeline. The only question is whether you can see what it's doing—and stop it when it goes too far.

[Register for the live webinar](https://thehacker.news/securing-agentic-ai?source=article)
and regain control of your AI stack before the next incident does it for you.

[Register for the Webinar ➜](https://thehacker.news/securing-agentic-ai?source=article)

Found this article interesting?

This article is a contributed piece from one of our valued partners.

Follow us on

[Google News](https://news.google.com/publications/CAAqLQgKIidDQklTRndnTWFoTUtFWFJvWldoaFkydGxjbTVsZDNNdVkyOXRLQUFQAQ)

,

[Twitter](https://twitter.com/thehackersnews)

and

[LinkedIn](https://www.linkedin.com/company/thehackernews/)

to read more exclusive content we post.