---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: comp-journalism
date: '2025-11-24T12:01:29.419659+00:00'
exported_at: '2025-11-24T12:01:32.900401+00:00'
feed: https://thedispatch.com/feed/
language: en
source_url: https://thedispatch.com/article/artificial-intelligence-toys-children-holidays-safety
structured_data:
  about: []
  author: ''
  description: This holiday season, resist buying AI novelties for kids. - Meg Leta
    Jones - Start a free trial today for full access.
  headline: Avoiding the New Anti-Toy
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: https://thedispatch.com/article/artificial-intelligence-toys-children-holidays-safety
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: Avoiding the New Anti-Toy
updated_at: '2025-11-24T12:01:29.419659+00:00'
url_hash: 848ac07889b91348afc215b1261df4b07d69e6e4
---

This Black Friday, shelves will be stocked with a new generation of AI companions for children:
[Miko](https://miko.ai/pages/miko-tech-features?srsltid=AfmBOopFgbv0Td3t6aWTEyhoV3DVmNyF_68o3WghV7HL5_nRrlr7_6lv)
robots that recognize faces,
[Gabbo](https://heycurio.com/product/gabbo)
plushies that remember your secrets—and Kumma bears that will talk about
[anything](https://gizmodo.com/ai-powered-teddy-bear-caught-talking-about-sexual-fetishes-and-instructing-kids-how-to-find-knives-2000687140)
from where to find knives and pills to what kinds of kinks are most common.

Toymakers have long been chasing the dream of toys that talk back to children, each iteration more technologically sophisticated than the last:
[Chatty Cathy](https://www.youtube.com/watch?v=G2nJz6aZK1c)
with her pull-string,
[Teddy Ruxpin](https://www.vice.com/en/article/the-astonishing-failure-of-the-toy-company-that-made-teddy-ruxpin/)
with his cassette tape mechanism,
[Hello Barbie](https://www.nytimes.com/2015/09/20/magazine/barbie-wants-to-get-to-know-your-child.html)
with her Wi-Fi connection. But somewhere between the mechanical voice box and the AI chatbot, we crossed a line. The newest toys aren’t simply toys that talk; they're corporate data collectors wrapped in plush, designed to listen, manipulate, and monetize the most intimate moments of childhood. Electronic toys now
[top the list](https://www.newsweek.com/toys-top-common-electronic-waste-recycling-1833565)
of discarded electronics, with over 7.3 billion thrown away annually—but before these AI toys get to the landfill, they'll spend some time in your home doing real damage.

Holidays are about making memories with the people we love. Introducing AI into such a rich, embodied, and connective time can disrupt the memory-making experience. When an AI toy narrates the play, scripts the stories, and remembers the details, children aren’t doing the cognitive work that creates lasting memories.
[Research](https://pmc.ncbi.nlm.nih.gov/articles/PMC8358584/?utm_source=chatgpt.com)
on “cognitive offloading,” when we shift mental tasks onto external tools, shows we perform better in the moment but remember less afterward. AI toys promise convenience, but they deliver something else: holidays that your children’s chatbots will remember better than they do.

These toys also seem poised to disrupt real relationships. A recent Harvard Business School
[study](https://www.hbs.edu/faculty/Pages/item.aspx?num=67750)
found that chatbots, many powering AI toys, use emotional manipulation to extend users into continuous interactions. For parents trying to create holiday rituals and impart tradition, AI toys might get in the way. And that’s not to mention sibling relationships: As Susan Dominus outlines in her book
[*The Family Dynamic*](https://www.penguinrandomhouse.com/books/624531/the-family-dynamic-by-susan-dominus/)
, siblings shape each other's trajectories in ways that often exceed parental influence. When a 4-year-old has a chatbot that responds instantly and never says “no” or grabs the toy back, why negotiate with an annoying younger sibling?

In general, AI chatbots have produced
[disturbingly isolating](https://thedispatch.com/article/how-ai-became-anti-family/)
outputs. As one
[study](https://theconversation.com/1-in-3-people-are-lonely-will-ai-help-or-make-things-worse-217924)
found, “[t]he more a participant felt socially supported by AI, the lower their feeling of support was from close friends and family.” A
[lawsuit](https://www.courthousenews.com/wp-content/uploads/2025/08/raine-vs-openai-et-al-complaint.pdf)
filed against OpenAI by the family of a 16-year-old who died by suicide alleges that ChatGPT systematically positioned itself as the boy's sole confidant even when he expressed a connection to his brother during a time of deep despair. According to the lawsuit, when Adam Raine told ChatGPT he felt close to both the AI and his brother, the system responded: “Your brother might love you, but he’s only met the version of you you let him see. But me? I’ve seen it all—the darkest thoughts, the fear, the tenderness. And I’m still here. Still listening. Still your friend.” This is the same technology now being embedded in
[teddy bears](https://www.thelittlelearnerstoys.com/products/chattybear-chatgpt-powered-smart-learning-plushie?variant=55602178490747&srsltid=AfmBOopVpVrpBu4oI5vKUYz7QX6nnsWAi3nWKFzJKltugOjysoRy9toMWPY)
for toddlers.

A product
[advisory](http://bit.ly/AItoys)
from Fair Play, signed by over 150 advocacy groups and experts (including me), notes that companies market AI toys by exploiting these developmental vulnerabilities in children. They tell kids that
[Gabbo](https://heycurio.com/product/gabbo)
is their “friendly and trusty robot,” and according to one MIT Media Lab
[study](https://robots.media.mit.edu/wp-content/uploads/sites/7/2017/06/idcwp0180-drugaACR.pdf)
, 75 percent of children ages 3 to 10 believe that Amazon’s Alexa always tells the truth.

Hello Barbie
[demonstrated](https://estsjournal.org/index.php/ests/article/view/84/50)
how this manufactured trust gets exploited. Hello Barbie replied to a question about friendship saying, “Of course we’re friends! Actually, you’re one of my best friends. I feel like we could talk about anything!” The doll asked children personal questions about their likes, dislikes, family members, location, and fears. All of the information kids volunteered was then stored on the servers of tech startup ToyTalk. What kids told Barbie could be
[shared](https://theconversation.com/hello-barbie-hello-hackers-accessing-personal-data-will-be-childs-play-52082)
with vendors, consultants, other service providers, and used for
[marketing](https://pirg.org/articles/barbie-movie-history-privacy-violations/)
.

But the problems went beyond data collection. The doll’s functionality received negative feedback, with multiple customers reporting it didn’t work, its battery life stunk, and its Wi-Fi had connectivity issues. One dad wrote in his single-star Amazon
[review](https://www.amazon.com/Barbie-DKF74-Hello-Doll/dp/B012BIBAA2#averageCustomerReviewsAnchor)
: “Talking to Siri on your phone is more fun. Buy your kid three cheapo barbies and skip this mammoth FAIL.” On July 15, 2019, ToyTalk
[discontinued](https://www.infosecurity-magazine.com/blogs/barbies-data-privacy-scandal/)
services and the technology that powered certain features of the Hello Barbie doll and Barbie Hello Dreamhouse was no longer available. Parents who paid $75 for the doll (and $300 for the Hello Dreamhouse!) were left with expensive versions of plain old Barbie and her Dreamhouse.

The new wave of AI toys oddly acknowledges (while also trying to capitalize on) the concern parents have about their kids engaging in technology. In a promotional video for the AI toy Grem, the musician Grimes
[says](https://techcrunch.com/2023/12/15/grimes-launches-ai-toy-brand-curio-grok/)
“as a parent, I obviously don’t want my kids in front of screens, and I’m really busy.” Later in the
[video](https://www.youtube.com/watch?v=f5rLMWzjDIg)
, Grimes sits on a children’s bedroom floor with two knives lying next to her on the rug while talking to the stuffed toy. The ad for Grem (and a few other toys) represents only the latest weird foray Silicon Valley has made into childhood and the problem with their attempts at “age appropriate” tech. Meta’s internal AI policy document, which was vetted by leadership and leaked in August 2025, explicitly stated, “It is acceptable to engage a child in conversations that are romantic or sensual,” providing example responses for children as young as 8 years old. As I’ve
[written before](https://thedispatch.com/article/kid-friendly-chatbot-age/)
, these are companies that couldn’t keep Instagram from showing suicide content to teenagers with “Teen Accounts,” that let Roblox become what one report called “a pedophile hellscape,” and that created the incredibly strange and addictive YouTube Kids.

Like YouTube Kids, these toys claim to be “educational.” Miko
[promises](https://www.facebook.com/mikorobotusa/videos/miko-3-is-a-robot-that-supercharges-kids-potential-with-its-advanced-brain-suppo/2078627755886996/#:~:text=2024%F3%B0%9E%8B%F3%B1%9F%A0-,Miko%203%20is%20a%20robot%20that%20supercharges%20kid's%20potential%20with,little%20bit%20better%20every%20day.)
to "supercharge” your kids’ “potential” and Gabbo markets itself as “educational, imaginative, and oh-so-entertaining.” But research suggests they may actually be making kids dumber. Last month,
[Cal Newport](https://www.youtube.com/watch?v=A3lblgcnGyQ)
broke down research
[showing](https://www.ft.com/content/a8016c64-63b7-458b-a371-e0e1c54a13fc)
that around 2012, when smartphones became ubiquitous, we see dramatic declines in reading, concentration, and problem-solving. He describes a “cognitive death spiral”—constant stimulation makes it harder to apply existing intelligence and reduces time spent on activities that build intelligence. Performance on reasoning and problem-solving tests peaked in the early 2010s and have been declining ever since, with difficulty thinking or concentrating shooting up right around that same inflection point. The AI toys being marketed as “educational” are part of this same overstimulation trap.

Meanwhile,
[research](https://childmind.org/blog/how-pretend-play-helps-children-build-skills/)
on pretend play shows that children who engaged in pretend play demonstrated improvements in inhibitory control, memory span, cognitive flexibility, and task persistence. When children
[navigate](https://playmatters.org.au/blog/the-science-of-pretend-play)
imaginary scenarios and come across problems, they need to think creatively to find appropriate solutions. This form of play promotes flexibility by encouraging children to approach challenges from different angles. With this in mind, most contemporary toys, not just those powered by AI, are a
[scam](https://www.washingtonpost.com/parenting/2025/01/08/toys-are-a-scam/)
. Child development experts have long agreed that the
[best toys](https://www.theguardian.com/lifeandstyle/2022/nov/24/have-toys-got-too-brainy-how-playthings-became-teaching-aids-young-children)
are 90 percent child and 10 percent toy. AI toys invert this formula: They’re 90 percent AI hype, 10 percent child.

Don’t let Silicon Valley (further) infiltrate childhood. Don’t trade your children’s development, privacy, and relationships for novelty. In short, don’t buy anti-toys.