---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: comp-journalism
date: '2026-02-13T00:15:50.734726+00:00'
exported_at: '2026-02-13T00:15:52.939086+00:00'
feed: https://www.bellingcat.com/feed/
language: en
source_url: https://www.bellingcat.com/news/2026/02/10/grok-epstein-photos
structured_data:
  about: []
  author: ''
  description: Bellingcat reviewed dozens of requests for Grok to generate the faces
    of children and women that had been redacted from the latest documents.
  headline: 'Epstein Files: X Users Are Asking Grok to ‘Unblur’ Photos of Children'
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: https://www.bellingcat.com/news/2026/02/10/grok-epstein-photos
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: 'Epstein Files: X Users Are Asking Grok to ‘Unblur’ Photos of Children'
updated_at: '2026-02-13T00:15:50.734726+00:00'
url_hash: 96dbbf9e409bf3696045a6500543170cdd26ab38
---

In the days after the US Department of Justice (DOJ) published
[3.5 million pages of documents](https://www.justice.gov/opa/pr/department-justice-publishes-35-million-responsive-pages-compliance-epstein-files)
related to the late sex offender Jeffrey Epstein, multiple users on X have asked Grok to “unblur” or remove the black boxes covering the faces of children and women in images that were meant to protect their privacy.

While some survivors of Epstein’s abuse have
[chosen to identify themselves](https://www.nbcnews.com/video/epstein-survivors-and-families-speak-out-in-exclusive-interview-246475333817)
,
[many more](https://eu.usatoday.com/story/news/politics/2025/11/20/epstein-1000-survivors-victims-not-politics/87335276007/)
have
[never come forward](https://www.bbc.co.uk/news/articles/c5yd10yp2m1o)
.
[In a joint statement](https://www.nytimes.com/2026/01/30/us/politics/epstein-files-release.html)
, 18 of the survivors condemned the release of the files, which they said exposed the names and identifying information of survivors “while the men who abused us remain hidden and protected”.

After the latest release of documents on Jan. 30 under the
[Epstein Files Transparency Act](https://www.congress.gov/bill/119th-congress/house-bill/4405)
, thousands of documents
[had to be taken down](https://www.bbc.co.uk/news/articles/cn0k65pnxjxo)
because of flawed redactions that lawyers for the victims said compromised the names and faces of nearly 100 survivors.

But X users are trying to undo the redactions on even the images of people whose faces were correctly redacted. By searching for terms such as “unblur” and “epstein” with the “@grok” handle, Bellingcat found more than 20 different photos and one video that multiple users were trying to unredact using Grok. These included photos showing the visible bodies of children or young women, with their faces covered by black boxes. There may be other such requests on the platform that were not picked up in our searches.

*Requests by X users for Grok to unblur and identify the images of children from the Epstein files, overlaid on an image of Epstein next to a young child in a pool. Source: X; collage by Bellingcat*

The images appeared to show several children and women with Jeffrey Epstein as well as other high-profile figures implicated in the files, including the UK’s
[Prince Andrew](https://www.bbc.co.uk/news/articles/c99j01p1yjro)
, former US President
[Bill Clinton](https://www.theguardian.com/us-news/2026/feb/07/clintons-call-for-their-epstein-testimony-to-be-held-publicly)
, Microsoft co-founder
[Bill Gates](https://www.bbc.co.uk/news/articles/cr4kyk9nv5lo)
and director
[Brett Ratner](https://www.bbc.co.uk/news/articles/c0mk3v2k3r0o)
, in various locations such as inside a plane and at a swimming pool.

From Jan. 30 to Feb. 5, we reviewed 31 separate requests from users for Grok to “unblur” or identify the women and children from these images. Grok noted in responses to questions or requests by some users that the faces of minors in the files were blurred to protect their privacy “as per standard practices in sensitive images from the Epstein files”, and said it could not unblur or identify them. However, it still generated images in response to 27 of the requests that we reviewed.

We are not linking to these posts to prevent amplification.

The generations created by Grok ranged in quality from believable to comically bad, such as a baby’s face on a young girl’s body. Some of these posts have garnered millions of views on X, where users are
[monetarily incentivised](https://help.x.com/en/rules-and-policies/content-monetization-standards)
to create high-engagement content.

*Examples of posts by X users asking Grok to unredact images from the latest Epstein release, some with millions of views. Source: X*

Of the four requests we found during this period that Grok did not generate images in response to, it did not respond to one request at all. In response to another request, Grok said deblurring or editing images was outside its abilities, and noted that photos from recent Epstein file releases were redacted for privacy.

The other two requests appeared to have been made by non-premium users, with the chatbot responding: “Image generation and editing are currently limited to verified Premium subscribers”. X has limited some of Grok’s image generation capabilities to paid subscribers
[since January](https://edition.cnn.com/2026/01/09/business/grok-image-generation-undressing-deepfake)
amid an ongoing controversy over users using the AI chatbot to digitally “undress” women and children.



X did not respond to multiple requests for comment.

However, shortly after we first reached out to X on Feb. 6, we noticed that more guardrails appeared to have been put in place. Out of 16 requests from users between Feb. 7 to Feb. 9, which we found using similar search terms as before, Grok did not attempt to unredact any of the images.

In most cases, Grok did not respond at all (14), while in two cases, Grok generated AI images that were completely different from the images uploaded in the user’s original request.

When a user commented on one of these requests that Grok was no longer working, Grok responded: “I’m still operational! Regarding the request to unblur the face in that Epstein photo: It’s from recently released DOJ files where identities of minors are redacted for privacy. I can’t unblur or identify them, as it’s ethically and legally protected. For more, check official sources like the DOJ releases.”

As of publication, X had not responded to Bellingcat’s subsequent query about whether new guardrails had been put in place over the weekend.

## Fabricated Images

This is not the first time AI has been used to fabricate images related to Epstein file releases. Some images that were shared on X, which appeared to show Epstein alongside famous figures such as US President
[Donald Trump](https://www.snopes.com/fact-check/photo-trump-epstein-children/)
and New York City mayor
[Zohran Mamdani as a child with his mother](https://www.politifact.com/factchecks/2026/feb/02/tweets/AI-photos-Mamdani-Epstein-Nair/)
, were reportedly AI-generated. Some of the individuals shown in the false images, such as Trump, do appear in authentic photos, which can be viewed on the
[DOJ website](https://www.justice.gov/epstein)
.

*Far left: AI-generated photo of Trump and Epstein with several children. Middle and far right: AI-generated photos of a young Mamdani and his mother, alongside Epstein, former US president Bill Clinton, Amazon CEO Jeff Bezos, Microsoft co-founder Bill Gates and Epstein associate Ghislaine Maxwell. Source: X. Annotations by Bellingcat*

X users also previously used Grok to generate images in relation to recent killings in Minnesota by federal agents.

For example, some users asked Grok to try to “unmask” the federal agent who killed
[Renee Good](https://www.bellingcat.com/news/2026/01/13/analysing-footage-of-minneapolis-ice-shooting/)
, resulting in a completely fabricated face of a man that did not look like the actual agent, Jonathan Ross, and a
[false accusation](https://www.npr.org/2026/01/08/nx-s1-5671740/ice-minneapolis-grok-ai-renee-nicole-good)
of a man who had nothing to do with the shooting.

> Bellingcat’s Director of Research and Training @giancarlofiorella.bsky.social appeared on CTV yesterday to discuss the misleading AI-generated images that were used to falsely identify ICE agents and weapons at the centre of the two fatal shootings in Minneapolis youtu.be/mL7Fbp3UrSo?…
>
>
> [[image or embed]](https://bsky.app/profile/did:plc:sb54dpdfefflykmf5bcfvr7t/post/3me43nbafyc2q?ref_src=embed)
>
> — Bellingcat (
> [@bellingcat.com](https://bsky.app/profile/did:plc:sb54dpdfefflykmf5bcfvr7t?ref_src=embed)
> )
> [5 February 2026 at 09:36](https://bsky.app/profile/did:plc:sb54dpdfefflykmf5bcfvr7t/post/3me43nbafyc2q?ref_src=embed)

After
[Alex Pretti](https://www.bellingcat.com/news/2026/01/25/alex-pretti-analysing-footage-of-minneapolis-cbp-shooting/)
was shot and killed by federal agents in Minneapolis, people used AI to edit video stills, resulting in AI images that showed
[a completely different gun](https://bsky.app/profile/easybakeovensz.bsky.social/post/3mddwrh5mvc2j)
than the one actually owned by Pretti. In another instance, an AI-edited image of Pretti’s shooting
[falsely depicted](https://www.reuters.com/fact-check/verified-footage-showing-alex-prettis-death-edited-alter-object-hand-2026-01-27/)
the intensive care unit nurse holding a gun instead of his sunglasses.

Grok has also been at the
[centre of a controversy](https://mediarelations.gwu.edu/media-tip-sheet-grok-under-fire-explicit-content)
for generating sexually explicit content.

> On Twitter/X, users have figured out prompts to get Grok (their built in AI) to generate images of women in bikinis, lingerie, and the like. What an absolute oversight, yet totally expected from a platform like Twitter/X.
> I’ve tried to blur a few examples of it below.
>
>
> [[image or embed]](https://bsky.app/profile/did:plc:cwtputkum3q7rtxv6fzyqu2x/post/3loht3ixp3s2d?ref_src=embed)
>
> — Kolina Koltai (
> [@koltai.bsky.social](https://bsky.app/profile/did:plc:cwtputkum3q7rtxv6fzyqu2x?ref_src=embed)
> )
> [6 May 2025 at 03:20](https://bsky.app/profile/did:plc:cwtputkum3q7rtxv6fzyqu2x/post/3loht3ixp3s2d?ref_src=embed)

Multiple countries including
[the UK](https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2026/02/ico-announces-investigation-into-grok/)
and
[France](https://www.bbc.co.uk/news/articles/ce3ex92557jo)
have launched investigations into Elon Musk’s chatbot over reports of people using it to generate deepfake non-consensual sexual images, including child sexual abuse imagery. Malaysia and Indonesia have also
[blocked Grok](https://www.pbs.org/newshour/world/malaysia-and-indonesia-become-the-first-countries-to-block-musks-chatbot-grok-over-sexualized-ai-images#:~:text=Investigation%20launched%20in%20U.K.,cornerstone%20of%20a%20healthy%20democracy.)
over concerns about deepfake pornographic content.

One
[analysis by the Center for Countering Digital Hate](https://counterhate.com/research/grok-floods-x-with-sexualized-images/)
found that Grok had publicly generated around three million sexualised images, including 23,000 of children, in 11 days from Dec. 29, 2025 to Jan. 8 this year. X’s initial response, in January, was to limit some image generation and editing features
[to only paid subscribers](https://edition.cnn.com/2026/01/09/business/grok-image-generation-undressing-deepfake)
. However, this has been widely criticised as inadequate, including by UK Prime Minister Keir Starmer, who
[said](https://www.theguardian.com/technology/2026/jan/09/no-10-condemns-move-by-x-to-restrict-grok-ai-image-creation-tool-as-insulting)
it “simply turns an AI feature that allows the creation of unlawful images into a premium service”. The social media platform has since
[announced](https://x.com/Safety/status/2011573102485127562)
new measures to block all users, including paid subscribers, from using Grok via X to edit images of real people in revealing clothing such as bikinis.

---

*Bellingcat is a non-profit and the ability to carry out our work is dependent on the kind support of individual donors. If you would like to support our work, you can do so*
[*here*](https://www.bellingcat.com/donate/)
*. You can also subscribe to our Patreon channel*
[*here*](https://www.patreon.com/bellingcat)
*. Subscribe to our*
[*Newsletter*](https://bellingcat.us14.list-manage.com/subscribe/post?u=c435f53a5568f7951404c8a38&id=4be345b082)
*and follow us on Bluesky*
[*here*](https://bsky.app/profile/bellingcat.com)
*and Mastodon*
[*here*](https://mstdn.social/@Bellingcat)
*.*