---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: ai-research
date: '2025-12-15T12:03:27.797432+00:00'
exported_at: '2025-12-15T12:03:30.216681+00:00'
feed: https://aws.amazon.com/blogs/machine-learning/feed
language: en
source_url: https://aws.amazon.com/blogs/machine-learning/building-a-voice-driven-aws-assistant-with-amazon-nova-sonic
structured_data:
  about: []
  author: ''
  description: In this post, we explore how to build a sophisticated voice-powered
    AWS operations assistant using Amazon Nova Sonic for speech processing and Strands
    Agents for multi-agent orchestration. This solution demonstrates how natural language
    voice interactions can transform cloud operations, making AWS services more accessible
    and operations more efficient.
  headline: Building a voice-driven AWS assistant with Amazon Nova Sonic
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: https://aws.amazon.com/blogs/machine-learning/building-a-voice-driven-aws-assistant-with-amazon-nova-sonic
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: Building a voice-driven AWS assistant with Amazon Nova Sonic
updated_at: '2025-12-15T12:03:27.797432+00:00'
url_hash: f1231da06f55ae0e3c90a1989752e73e314bfe91
---

As cloud infrastructure becomes increasingly complex, the need for intuitive and efficient management interfaces has never been greater. Traditional command-line interfaces (CLI) and web consoles, while powerful, can create barriers to quick decision-making and operational efficiency. What if you could speak to your AWS infrastructure and get immediate, intelligent responses?

In this post, we explore how to build a sophisticated voice-powered AWS operations assistant using
[Amazon Nova Sonic](https://docs.aws.amazon.com/nova/latest/userguide/speech.html)
for speech processing and
[Strands Agents](https://strandsagents.com/latest/documentation/docs/)
for multi-agent orchestration. This solution demonstrates how natural language voice interactions can transform cloud operations, making AWS services more accessible and operations more efficient.

The multi-agent architecture we demonstrate extends beyond basic AWS operations to support diverse use cases including customer service automation, internet-of-things (IoT) device management, financial data analysis, and enterprise workflow orchestration. This foundational pattern can be adapted for any domain requiring intelligent task routing and natural language interaction.

## Architecture deep dive

This section explores the technical architecture that powers our voice-driven AWS assistant. The following diagram illustrates how
[Amazon Nova Sonic](https://docs.aws.amazon.com/nova/latest/userguide/speech.html)
integrates with
[Strands Agents](https://strandsagents.com/latest/documentation/docs/)
to create a seamless multi-agent system that processes voice commands and executes AWS operations in real-time.

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/08/image-1-1.png)

## Core components

The multi-agent architecture consists of several specialized components that work together to process voice commands and execute AWS operations:

1. **Supervisor Agent**
   : Acts as the central coordinator, analyzing incoming voice queries and routing them to the appropriate specialized agent based on context and intent.
2. **Specialized Agents**
   :
   1. **EC2 Agent**
      : Handles instance management, status monitoring, and compute operations
   2. **SSM Agent**
      : Manages Systems Manager operations, command execution, and patch management
   3. **Backup Agent**
      : Oversees
      [AWS Backup](https://aws.amazon.com/backup/)
      configurations, job monitoring, and restore operations
3. **Voice Integration Layer**
   : Uses
   [Amazon Nova Sonic](https://docs.aws.amazon.com/nova/latest/userguide/speech.html)
   for bidirectional voice processing, converting speech to text for processing and text back to speech for responses.

## Solution overview

The Strands Agents Nova Voice Assistant demonstrates a new paradigm for AWS infrastructure management through conversational artificial intelligence (AI). Instead of navigating complex web consoles or memorizing CLI commands, users can simply speak their intentions and receive immediate responses. This solution bridges the gap between natural human communication and technical AWS operations, making cloud management accessible to both technical and non-technical team members.

## Technology stack

The solution uses modern, cloud-native technologies to deliver a robust and scalable voice interface:

* **Backend**
  : Python 3.12+ with
  [Strands Agents](https://strandsagents.com/latest/documentation/docs/)
  framework for agent orchestration
* **Frontend**
  : React with
  [AWS Cloudscape Design System](https://cloudscape.design/)
  for consistent AWS UI/UX
* **AI models**
  :
  [Amazon Bedrock](https://aws.amazon.com/bedrock)
  and Claude 3 Haiku for natural language understanding and generation
* **Voice processing**
  :
  [Amazon Nova Sonic](https://docs.aws.amazon.com/nova/latest/userguide/speech.html)
  for high-quality speech synthesis and recognition
* **Communication**
  : WebSocket server for real-time bidirectional communication

## Key features and capabilities

Our voice-driven assistant offers several advanced features that make AWS operations more intuitive and efficient. The system understands natural voice queries and converts them into appropriate AWS API calls. For example:

* “Show me all running EC2 instances in us-east-1”
* “Install
  [Amazon CloudWatch](https://aws.amazon.com/cloudwatch/)
  agent using SSM on my Dev instances”
* “Check the status of last night’s backup jobs”

The responses are specifically optimized for voice delivery, with concise summaries limited to 800 characters, clear structured information delivery, and conversational phrasing that sounds natural when spoken aloud (avoiding technical jargon and using complete sentences suitable for speech synthesis).

## Implementation overview

Getting started with the voice-driven AWS assistant involves three main steps:

### Environment setup

* Configure AWS credentials with access to Bedrock, Nova Sonic, and target AWS services
* Set up Python 3.12+ backend environment and React frontend
* Ensure proper
  [AWS Identity and Access Management (IAM)](https://aws.amazon.com/iam/)
  permissions for multi-agent operations

### Launch the application

* Start the Python WebSocket server for voice processing
* Launch the React frontend with AWS Cloudscape components
* Configure voice settings and WebSocket connections

### Begin voice interactions

* Grant browser microphone permissions for voice input
* Test with example commands like “List my EC2 instances” or “Check backup status”
* Experience real-time voice responses through
  [Amazon Nova Sonic](https://docs.aws.amazon.com/nova/latest/userguide/speech.html)

Ready to build your own? Complete deployment instructions, code examples, and troubleshooting guides are available in the
[GitHub repository.](https://github.com/aws-samples/sample-aws-strands-nova-voice-assistant)

## Example prompts to test through audio

Test your voice assistant with these example commands:

### EC2 instance management:

* “List my dev EC2 instances where tag key is ‘env'”
* “What’s the status of those instances?”
* “Start those instances”
* “Do these instances have SSM permissions?”

### Backup management:

* “Make sure these instances are backed up daily”

### SSM management:

* “Install CloudWatch agent using SSM on these instances”
* “Scan these instances for patches using SSM”

## Demo video

The following video demonstrates the voice assistant in action, showing how natural language commands are processed and executed against AWS services via real-time voice interaction, agent coordination, and AWS API responses.

[

](https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-19180/nova-sonic-blog-final.mp4?_=1)

## Implementation examples

The following code examples demonstrate key integration patterns and best practices for implementing your voice-driven AWS assistant. These examples show how to integrate Amazon Nova Sonic for voice processing and configure the supervisor agent for intelligent task routing.

## AWS Strands Agents setup

The implementation uses a multi-agent orchestrator pattern with specialized agents:

```
from strands import Agent
from config.conversation_config import ConversationConfig
from config.config import create_bedrock_model

class SupervisorAgent(Agent):
    def __init__(self, specialized_agents, config=None):
        bedrock_model = create_bedrock_model(config)
        conversation_manager = ConversationConfig.create_conversation_manager("supervisor")

        super().__init__(
            model=bedrock_model,
            system_prompt=self._get_routing_instructions(),
            tools=[],  # No tools for pure router
            conversation_manager=conversation_manager,
        )
        self.specialized_agents = specialized_agents
```

## Nova Sonic integration

The implementation uses a WebSocket server with session management for real-time voice processing:

```
class S2sSessionManager:
    def __init__(self, model_id='amazon.nova-sonic-v1:0', region='us-east-1', config=None):
        self.model_id = model_id
        self.region = region
        self.audio_input_queue = asyncio.Queue()
        self.output_queue = asyncio.Queue()
        self.supervisor_agent = SupervisorAgentIntegration(config)

    async def processToolUse(self, toolName, toolUseContent):
        if toolName == "supervisoragent":
            result = await self.supervisor_agent.query(content)
            if len(result) > 800:
                result = result[:800] + "... (truncated for voice)"
            return {"result": result}
```

## Security best practices

This solution is designed for development and testing purposes. Before deploying to production environments, implement appropriate security controls including:

* Authentication and authorization mechanisms
* Network security controls and access restrictions
* Monitoring and logging for audit compliance
* Cost controls and usage monitoring

**Note:**
Always follow AWS security best practices and the principle of least privilege when configuring IAM permissions.

## Production Considerations

While this solution demonstrates Strands Agents capabilities using a development-focused deployment approach, organizations planning production implementations should consider
[Amazon Bedrock AgentCore](https://aws.amazon.com/bedrock/agentcore/)
[Runtime](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/agents-tools-runtime.html)
for enterprise-grade hosting and management.
[Amazon Bedrock AgentCore](https://aws.amazon.com/bedrock/agentcore/)
Benefits for production deployment:

* Serverless runtime: Purpose-built for deploying and scaling dynamic AI agents without managing infrastructure
* Session isolation: Complete session isolation with dedicated microVMs for each user session, critical for agents performing privileged operations
* Auto-scaling: Scale up to thousands of agent sessions in seconds with pay-per-usage pricing
* Enterprise security: Built-in security controls with seamless integration to identity providers (
  [Amazon Cognito](https://aws.amazon.com/cognito/)
  , Microsoft Entra ID, Okta)
* Observability: Built-in distributed tracing, metrics, and debugging capabilities through Cloudwatch integration
* Session persistence: Highly reliable with session persistence for long-running agent interactions

For organizations ready to move beyond development and testing,
[Amazon Bedrock AgentCore](https://aws.amazon.com/bedrock/agentcore/)
Runtime provides the production-ready foundation needed to deploy voice-driven AWS assistants at enterprise scale.

## Integration with additional AWS services

The system can be extended to support additional AWS services:

## Conclusion

The
[Strands Agents](https://strandsagents.com/latest/documentation/docs/)
Nova Voice Assistant demonstrates the powerful potential of combining voice interfaces with intelligent agent orchestration across diverse domains. By leveraging
[Amazon Nova Sonic](https://docs.aws.amazon.com/nova/latest/userguide/speech.html)
for speech processing and
[Strands Agents](https://strandsagents.com/latest/documentation/docs/)
for multi-agent coordination, organizations can create more intuitive and efficient ways to interact with complex systems and workflows.

This foundational architecture extends far beyond cloud operations to enable voice-driven solutions for customer service automation, financial analysis, IoT device management, healthcare workflows, supply chain optimization, and countless other enterprise applications. The combination of natural language processing, intelligent routing, and specialized domain knowledge creates a versatile platform for transforming how users interact with any complex system. The modular architecture ensures scalability and extensibility, allowing organizations to customize the solution for their specific domains and use cases. As voice interfaces continue to evolve and AI capabilities advance, solutions like this are likely to become increasingly important for managing complex environments across all industries.

## Getting Started

Ready to build your own voice-powered AWS operations assistant? The complete source code and documentation are available in the
[GitHub repository.](https://github.com/aws-samples/sample-aws-strands-nova-voice-assistant)
Follow this implementation guide to get started, and don’t hesitate to customize the solution for your specific use cases.

For questions, feedback, or contributions, please visit the project repository or reach out through the AWS community forums.

---

### About the authors:

**![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/10/jagdish.png)
Jagdish Komakula**
is a passionate Sr. Delivery Consultant working with AWS Professional Services. With over two decades of experience in Information Technology, he helped numerous enterprise clients successfully navigate their digital transformation journeys and cloud adoption initiatives.

**![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/10/aditya.png)
Aditya Ambati**
is an experienced DevOps Engineer with 14 plus years of experience in IT. He has an excellent reputation for resolving problems, improving customer satisfaction, and driving overall operational improvements.

**![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/10/anand.png)
Anand Krishna Varanasi**
is a seasoned AWS builder and architect who began his career over 17 years ago. He guides customers with cutting-edge cloud technology migration strategies (the
[7 Rs](https://docs.aws.amazon.com/prescriptive-guidance/latest/migration-retiring-applications/apg-gloss.html#apg.migration.terms)
) and modernization. He is passionate about the role that technology plays in bridging the present with all the possibilities for our future.

**![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/10/phani-kumar.jpeg)
D.T.V.R.L Phani Kumar**
is a visionary DevOps Consultant with 10+ years of groundbreaking technology leadership, specializing in transformative automation strategies. As a distinguished engineer, he expertly bridges AI/ML innovations with DevOps practices, consistently delivering revolutionary solutions that redefine operational excellence and customer experiences. His strategic approach and technical mastery have positioned him as a thought leader in driving technological paradigm shifts.