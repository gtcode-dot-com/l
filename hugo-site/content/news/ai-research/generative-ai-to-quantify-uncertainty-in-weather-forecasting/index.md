---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: ai-research
date: '2025-11-12T22:51:26.283271+00:00'
exported_at: '2025-11-12T22:54:41.547227+00:00'
feed: http://feeds.feedburner.com/blogspot/gJZg
language: en
source_url: http://blog.research.google/2024/03/generative-ai-to-quantify-uncertainty.html
structured_data:
  about: []
  author: ''
  description: Generative AI to quantify uncertainty in weather forecasting
  headline: Generative AI to quantify uncertainty in weather forecasting
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: http://blog.research.google/2024/03/generative-ai-to-quantify-uncertainty.html
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: Generative AI to quantify uncertainty in weather forecasting
updated_at: '2025-11-12T22:51:26.283271+00:00'
url_hash: 377c4894f4c7aa1661365498d10d969d3340d60b
---

In December 1972, at the
[American Association for the Advancement of Science](https://www.aaas.org/)
meeting in Washington, D.C., MIT meteorology professor
[Ed Lorenz](https://en.wikipedia.org/wiki/Edward_Norton_Lorenz)
gave a talk entitled, “Does the Flap of a Butterfly's Wings in Brazil Set Off a Tornado in Texas?”, which contributed to the term “
[butterfly effect](https://en.wikipedia.org/wiki/Butterfly_effect)
”. He was building on his earlier, landmark 1963 paper where he examined the feasibility of “very-long-range weather prediction” and described how errors in initial conditions grow exponentially when integrated in time with numerical weather prediction models. This exponential error growth, known as chaos, results in a deterministic predictability limit that restricts the use of individual forecasts in decision making, because they do not quantify the inherent uncertainty of weather conditions. This is particularly problematic when forecasting extreme weather events, such as hurricanes, heatwaves, or floods.

Recognizing the limitations of deterministic forecasts, weather agencies around the world issue
*probabilistic forecasts*
. Such forecasts are based on ensembles of deterministic forecasts, each of which is generated by including synthetic noise in the initial conditions and stochasticity in the physical processes. Leveraging the fast error growth rate in weather models, the forecasts in an ensemble are purposefully different: the initial uncertainties are tuned to generate runs that are as different as possible and the stochastic processes in the weather model introduce additional differences during the model run. The error growth is mitigated by averaging all the forecasts in the ensemble and the variability in the ensemble of forecasts quantifies the uncertainty of the weather conditions.

While effective, generating these probabilistic forecasts is computationally costly. They require running highly complex numerical weather models on massive supercomputers multiple times. Consequently, many operational weather forecasts can only afford to generate ~10–50 ensemble members for each forecast cycle. This is a problem for users concerned with the likelihood of rare but high-impact weather events, which typically require much larger ensembles to assess beyond a few days. For instance, one would need a 10,000-member ensemble to forecast the likelihood of events with 1% probability of occurrence with a relative error less than 10%. Quantifying the probability of such extreme events could be useful, for example, for emergency management preparation or for energy traders.