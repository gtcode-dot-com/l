---
ai_commentary: []
ai_commentary_meta:
  content_digest: ''
  generated_at: ''
  model: ''
  prompt_version: ''
  provider: ''
category: ai-research
date: '2025-12-25T00:03:33.124361+00:00'
exported_at: '2025-12-25T00:03:36.345043+00:00'
feed: https://aws.amazon.com/blogs/machine-learning/feed
language: en
source_url: https://aws.amazon.com/blogs/machine-learning/agentic-qa-automation-using-amazon-bedrock-agentcore-browser-and-amazon-nova-act
structured_data:
  about: []
  author: ''
  description: In this post, we explore how agentic QA automation addresses these
    challenges and walk through a practical example using Amazon Bedrock AgentCore
    Browser and Amazon Nova Act to automate testing for a sample retail application.
  headline: Agentic QA automation using Amazon Bedrock AgentCore Browser and Amazon
    Nova Act
  inLanguage: en
  keywords: []
  main_image: ''
  original_source: https://aws.amazon.com/blogs/machine-learning/agentic-qa-automation-using-amazon-bedrock-agentcore-browser-and-amazon-nova-act
  publisher:
    logo: /favicon.ico
    name: gtcode.com
title: Agentic QA automation using Amazon Bedrock AgentCore Browser and Amazon Nova
  Act
updated_at: '2025-12-25T00:03:33.124361+00:00'
url_hash: 97d224cdd0d037d15ac37ba9f62df715fc012801
---

Quality assurance (QA) testing has long been the backbone of software development, but traditional QA approaches haven’t kept pace with modern development cycles and complex UIs. Most organizations still rely on a hybrid approach combining manual testing with script-based automation frameworks like Selenium, Cypress, and Playwright—yet teams spend significant amount of their time maintaining existing test automation rather than creating new tests. The problem is that traditional automation is brittle. Test scripts break with UI changes, require specialized programming knowledge, and often provide incomplete coverage across browsers and devices. With many organizations actively exploring AI-driven testing workflows, current approaches are insufficient.

In this post, we explore how agentic QA automation addresses these challenges and walk through a practical example using
[Amazon Bedrock AgentCore Browser](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/browser-tool.html)
and
[Amazon Nova Act](https://nova.amazon.com/act)
to automate testing for a sample retail application.

## Benefits of agentic QA testing

Agentic AI shifts QA testing from rule-based automation to intelligent, autonomous testing systems. Unlike conventional automation that follows preprogrammed scripts, agentic AI can observe, learn, adapt, and make decisions in real time. The key advantages include autonomous test generation through UI observation and dynamic adaptation as UI elements change—minimizing the maintenance overhead that consumes QA teams’ time. These systems mimic human interaction patterns, making sure testing occurs from a genuine user perspective rather than through rigid, scripted pathways.

## AgentCore Browser for large-scale agentic QA testing

To realize the potential of agentic AI testing at enterprise scale, organizations need robust infrastructure that can support intelligent, autonomous testing agents. AgentCore Browser, a built-in tool of
[Amazon Bedrock AgentCore](https://aws.amazon.com/bedrock/agentcore/)
, addresses this need by providing a secure, cloud-based browser environment specifically designed for AI agents to interact with websites and applications.

AgentCore Browser includes essential enterprise security features such as session isolation, built-in observability through live viewing,
[AWS CloudTrail](http://aws.amazon.com/cloudtrail)
logging, and session replay capabilities. Operating within a containerized ephemeral environment, each browser instance can be shut down after use, providing clean testing states and optimal resource management. For large-scale QA operations, AgentCore Browser can run multiple browser sessions concurrently, so organizations can parallelize testing across different scenarios, environments, and user journeys simultaneously.

## Agentic QA with the Amazon Nova Act SDK

The infrastructure capabilities of AgentCore Browser become truly powerful when combined with an agentic SDK like Amazon Nova Act. Amazon Nova Act is an AWS service that helps developers build, deploy, and manage fleets of reliable AI agents for automating production UI workflows. With this SDK, developers can break down complex testing workflows into smaller, reliable commands while maintaining the ability to call APIs and perform direct browser manipulation as needed. This approach offers seamless integration of Python code throughout the testing process. Developers can interleave tests, breakpoints, and assertions directly within the agentic workflow, providing unprecedented control and debugging capabilities. This combination of the AgentCore Browser cloud infrastructure with the Amazon Nova Act agentic SDK creates a comprehensive testing ecosystem that transforms how organizations approach quality assurance.

## Practical implementation: Retail application testing

To illustrate this transformation in practice, let’s consider developing a new application for a retail company. We’ve created a mock retail web application to demonstrate the agentic QA process, assuming the application is hosted on AWS infrastructure within a private enterprise network during development and testing phases.

To streamline the test creation process, we use
[Kiro](https://kiro.dev/)
, an AI-powered coding assistant to automatically generate UI test cases by analyzing our application code base. Kiro examines the application structure, reviews existing test patterns, and creates comprehensive test cases following the JSON schema format required by Amazon Nova Act. By understanding the application’s features—including navigation, search, filtering, and form submissions—Kiro generates detailed test steps with actions and expected results that are immediately executable through AgentCore Browser. This AI-assisted approach dramatically accelerates test creation while providing comprehensive coverage. The following demonstration shows Kiro generating 15 ready-to-use test cases for our QA testing demo application.

[![Kiro generating test cases](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/15/video1_12_12.gif)](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/15/video1_12_12.gif)

After the test cases are generated, they are placed in the
[test data directory](https://github.com/aws-samples/amazon-nova-samples/tree/main/nova-act/usecases/qa-testing/tests/src/test_data)
where
[pytest](https://docs.pytest.org/en/stable/)
automatically discovers and executes them. Each JSON test file becomes an independent test that pytest can run in parallel. The framework uses
[pytest-xdist](https://pypi.org/project/pytest-xdist/)
to distribute tests across multiple worker processes, automatically utilizing available system resources for optimal performance.

During execution, each test gets its own isolated AgentCore Browser session through the Amazon Nova Act SDK. The Amazon Nova Act agent reads the test steps from the JSON file and executes them—performing actions like clicking buttons or filling forms, then validating that expected results occur. This data-driven approach means teams can create comprehensive test suites by simply writing JSON files, without needing to write Python code for each test scenario. The parallel execution architecture significantly reduces testing time. Tests that would normally run sequentially can now execute simultaneously across multiple browser sessions, with pytest managing the distribution and aggregation of results. An HTML report is automatically generated using pytest-html and the pytest-html-nova-act plugin, providing test outcomes, screenshots, and execution logs for complete visibility into the testing process.

![](https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-19972/ML-19972-video2.gif)

One of the most powerful capabilities of AgentCore Browser is its ability to run multiple browser sessions concurrently, enabling true parallel test execution at scale. When pytest distributes tests across worker processes, each test spawns its own isolated browser session in the cloud. This means your entire test suite can execute simultaneously rather than waiting for each test to complete sequentially.

The
[AWS Management Console](http://aws.amazon.com/console)
provides complete visibility into these parallel sessions. As demonstrated in the following video, you can view the active browser sessions running concurrently, monitor their status, and track resource utilization in real time. This observability is critical for understanding test execution patterns and optimizing your testing infrastructure.

![](https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-19972/ML-19972-video3.gif)

Beyond just monitoring session status, AgentCore Browser offers live view and session replay features to watch exactly what Amazon Nova Act is doing during and after test execution. For an active browser session, you can open the live view and observe the agent interacting with your application in real time—clicking buttons, filling forms, navigating pages, and validating results. When you enable session replay, you can view the recorded events by replaying the recorded session. This allows you to validate test results even after the test execution completes. These capabilities are invaluable for debugging test failures, understanding agent behavior, and gaining confidence in your automated testing process.

For complete deployment instructions and access to the sample retail application code,
[AWS CloudFormation](http://aws.amazon.com/cloudformation)
templates, and pytest testing framework, refer to the accompanying
[GitHub repository](https://github.com/aws-samples/amazon-nova-samples/tree/main/nova-act/usecases/qa-testing)
. The repository includes the necessary components to deploy and test the application in your own AWS environment.

## Conclusion

In this post, we walked through how AgentCore Browser can help parallelize agentic QA testing for web applications. An agent like Amazon Nova Act can perform automated agentic QA testing with high reliability.

---

### About the authors

**[![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/08/21/kosti.jpg)](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/08/21/kosti.jpg)
Kosti Vasilakakis**
is a Principal PM at AWS on the Agentic AI team, where he has led the design and development of several Bedrock AgentCore services from the ground up, including Runtime, Browser, Code Interpreter, and Identity. He previously worked on Amazon SageMaker since its early days, launching AI/ML capabilities now used by thousands of companies worldwide. Earlier in his career, Kosti was a data scientist. Outside of work, he builds personal productivity automations, plays tennis, and enjoys life with his wife and kids.

**[![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/02/20/VedaRaman-150x150-1-1.png)](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/10/07/VedaRaman.png)
Veda Raman**
is a Sr Solutions Architect for Generative AI for Amazon Nova and Agentic AI at AWS. She helps customers design and build Agentic AI solutions using Amazon Nova models and Bedrock AgentCore. She previously worked with customers building ML solutions using Amazon SageMaker and also as a serverless solutions architect at AWS.

[![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/17/nyalomka-high-res-current-photo-1.jpeg)](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/16/nyalomka-high-res-current-photo.jpeg)
**Omkar Nyalpelly**
is a Cloud Infrastructure Architect at AWS Professional Services with deep expertise in AWS Landing Zones and DevOps methodologies. His current focus centers on the intersection of cloud infrastructure and AI technologies—specifically leveraging Generative AI and agentic AI systems to build autonomous, self-managing cloud environments. Through his work with enterprise customers, Omkar explores innovative approaches to reduce operational overhead while enhancing system reliability. Outside of his technical pursuits, he enjoys playing cricket, baseball, and exploring creative photography. He holds an MS in Networking and Telecommunications from Southern Methodist University.

[![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/17/Ryan.png)](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/12/16/headshot.png)
**Ryan Canty**
is a Solutions Architect at Amazon AGI Labs with over 10 years of software engineering experience, specializing in designing and scaling enterprise software systems across multiple technology stacks. He works with customers to leverage Amazon Nova Act, an AWS service for building and deploying highly reliable AI agents that automate UI-based workflows at scale, bridging the gap between cutting-edge AI capabilities and practical business applications.