---
title: "Tutorial Part 2: Building the Parent SNOs"
description: "A code-heavy guide to manually constructing the Structured Narrative Objects for the Plate Tectonics and Geosyncline theories."
weight: 8
lastmod: "2025-07-30"
sitemap:
  changefreq: monthly
  priority: 0.7
  filename: sitemap.xml
---

This section establishes the **systematic SNO construction methodology** that serves as the template for DSPy automation. Each construction step demonstrates the quality control standards and structural requirements that must be maintained across n ≥ 30 automated synthesis pairs to ensure statistical validity.

The manual construction process provides the **quality benchmark** for automated generation, establishing the evidence standards, reasoning graph complexity, and hypothesis precision required for rigorous synthesis validation. This methodology will be encoded in DSPy optimization to maintain scientific rigor while scaling to statistically significant sample sizes.

### Setting Up the Environment

First, let's imagine our basic imports. We need tools for creating SNOs and a mock embedding function.

```python
# Hypothetical CNS 2.0 Tools Library
from cns_tools import StructuredNarrativeObject, ReasoningGraph, EvidenceSet
from cns_tools.utils import get_text_embedding

# We'll also need a unique identifier for our evidence
import hashlib

def hash_source(text):
    return hashlib.sha256(text.encode()).hexdigest()

# --- Mock Evidence Sources ---
# In a real scenario, these would be pointers to actual documents (e.g., DOIs).
# Here, we'll use hashes of hypothetical paper titles as placeholders.

EVIDENCE_HALL_1859 = hash_source("Hall, J. (1859). Palaeontology of New York.")
EVIDENCE_DANA_1873 = hash_source("Dana, J.D. (1873). On the origin of mountains.")
EVIDENCE_DIETZ_1961 = hash_source("Dietz, R.S. (1961). Continent and Ocean Basin Evolution by Spreading of the Sea Floor.")
EVIDENCE_VINE_1963 = hash_source("Vine, F.J. & Matthews, D.H. (1963). Magnetic Anomalies over Oceanic Ridges.")
EVIDENCE_WILSON_1965 = hash_source("Wilson, J.T. (1965). A new class of faults and their bearing on continental drift.")
```

### 1. Building `SNO_Geosyncline`

This SNO represents the classical, pre-1960s view of geology.

**Hypothesis:** Mountain ranges are formed by the vertical collapse and uplift of large, sediment-filled troughs (geosynclines) on a static, cooling Earth.

```python
# 1. Define the Hypothesis Embedding
# In a real system, this would be generated by a sophisticated language model.
hypothesis_geosyncline = "Mountain ranges are formed by the vertical collapse and uplift of large, sediment-filled troughs (geosynclines) on a static, cooling Earth."
H_geosyncline = get_text_embedding(hypothesis_geosyncline)

# 2. Build the Reasoning Graph (G)
G_geosyncline = ReasoningGraph(graph_id="G_Geo_v1")

# Add claims (nodes) to the graph
G_geosyncline.add_claim("c1", "The Earth is a cooling and contracting body.")
G_geosyncline.add_claim("c2", "Thick sedimentary deposits accumulate in large troughs (geosynclines).")
G_geosyncline.add_claim("c3", "The crust buckles under the sediment weight and compressional forces from cooling.")
G_geosyncline.add_claim("c4", "This buckling leads to vertical uplift, forming mountain ranges.")
G_geosyncline.add_claim("c5", "Continents and ocean basins are permanent, fixed features.")

# Add reasoning relationships (edges) between claims
G_geosyncline.add_edge("c1", "c3", "supports") # Cooling earth supports buckling
G_geosyncline.add_edge("c2", "c3", "supports") # Sediment accumulation supports buckling
G_geosyncline.add_edge("c3", "c4", "implies")  # Buckling implies uplift
G_geosyncline.add_edge("c5", "c1", "is_consistent_with") # Fixed continents are consistent with a simple cooling model

# 3. Populate the Evidence Set (E)
E_geosyncline = EvidenceSet(evidence_id="E_Geo_v1")
E_geosyncline.add_evidence(EVIDENCE_HALL_1859, "Supports the existence of thick sedimentary layers in mountain belts.", supports_claims=["c2"])
E_geosyncline.add_evidence(EVIDENCE_DANA_1873, "Provides a mechanism for compression and uplift.", supports_claims=["c3", "c4"])

# 4. Instantiate the SNO
# The Trust Score (T) is initially null, as it will be assigned by the Critic Pipeline.
SNO_geosyncline = StructuredNarrativeObject(
    hypothesis_embedding=H_geosyncline,
    reasoning_graph=G_geosyncline,
    evidence_set=E_geosyncline,
    trust_score=None # To be computed later
)

print("SNO_Geosyncline created successfully.")
```

### 2. Building `SNO_PlateTectonics`

This SNO represents the modern, revolutionary view.

**Hypothesis:** The Earth's surface is composed of rigid lithospheric plates that move, and their interactions at boundaries are the primary cause of mountain building, earthquakes, and volcanism.

```python
# 1. Define the Hypothesis Embedding
hypothesis_tectonics = "The Earth's surface is composed of rigid lithospheric plates that move, and their interactions at boundaries are the primary cause of mountain building, earthquakes, and volcanism."
H_tectonics = get_text_embedding(hypothesis_tectonics)

# 2. Build the Reasoning Graph (G)
G_tectonics = ReasoningGraph(graph_id="G_PT_v1")

# Add claims (nodes)
G_tectonics.add_claim("c1", "The lithosphere is divided into rigid plates.")
G_tectonics.add_claim("c2", "New oceanic crust is generated at mid-ocean ridges (seafloor spreading).")
G_tectonics.add_claim("c3", "Oceanic crust is consumed at subduction zones.")
G_tectonics.add_claim("c4", "Plate motion is driven by mantle convection.")
G_tectonics.add_claim("c5", "Mountain ranges are formed by the collision of continental plates or subduction.")
G_tectonics.add_claim("c6", "The continents are not fixed but drift over time.")

# Add reasoning relationships (edges)
G_tectonics.add_edge("c2", "c1", "supports")
G_tectonics.add_edge("c3", "c1", "supports")
G_tectonics.add_edge("c1", "c5", "implies")
G_tectonics.add_edge("c4", "c1", "provides_mechanism_for")
G_tectonics.add_edge("c2", "c6", "implies") # Seafloor spreading implies continental drift

# This is a key point of conflict with the other SNO
G_tectonics.add_claim("c7_conflict", "Continents and ocean basins are NOT permanent, fixed features.")
G_tectonics.add_edge("c6", "c7_conflict", "implies")

# 3. Populate the Evidence Set (E)
E_tectonics = EvidenceSet(evidence_id="E_PT_v1")
E_tectonics.add_evidence(EVIDENCE_DIETZ_1961, "Proposes the mechanism of seafloor spreading.", supports_claims=["c2"])
E_tectonics.add_evidence(EVIDENCE_VINE_1963, "Symmetrical magnetic stripes around mid-ocean ridges provide strong proof of seafloor spreading.", supports_claims=["c2"])
E_tectonics.add_evidence(EVIDENCE_WILSON_1965, "Identifies transform faults, a necessary component of plate boundary interactions.", supports_claims=["c1", "c5"])

# 4. Instantiate the SNO
SNO_plate_tectonics = StructuredNarrativeObject(
    hypothesis_embedding=H_tectonics,
    reasoning_graph=G_tectonics,
    evidence_set=E_tectonics,
    trust_score=None # To be computed later
)

print("SNO_PlateTectonics created successfully.")
```

### DSPy Automation Template for Statistical Scaling

This manual construction establishes the **quality control template** for DSPy-automated generation across n=30+ validation pairs:

```python
# DSPy signature for systematic SNO generation
class StatisticalSNOGenerator(dspy.Signature):
    """Generate high-quality opposing SNOs for statistical synthesis validation."""
    
    debate_specification = dspy.InputField(desc="Scientific debate with documented resolution and primary sources")
    quality_requirements = dspy.InputField(desc="Evidence standards, reasoning complexity, hypothesis precision")
    validation_framework = dspy.InputField(desc="Ground truth criteria and success metrics")
    
    sno_historical = dspy.OutputField(desc="SNO representing historical/minority position")
    sno_modern = dspy.OutputField(desc="SNO representing accepted/majority position") 
    quality_metrics = dspy.OutputField(desc="Evidence count, reasoning depth, source authenticity scores")
    validation_criteria = dspy.OutputField(desc="Measurable synthesis success criteria")

# Quality control parameters derived from manual prototype:
QUALITY_STANDARDS = {
    'min_evidence_sources': 3,  # Based on manual SNO construction
    'min_reasoning_nodes': 5,   # Complexity threshold from prototype
    'hypothesis_precision': 0.9, # Semantic clarity requirement
    'source_authenticity': 0.95, # Historical accuracy standard
    'dialectical_opposition': 0.8 # CScore threshold for valid pairs
}

# Domain expansion for statistical validation:
VALIDATION_DOMAINS = [
    {'domain': 'geology', 'debate': 'plate_tectonics_vs_geosyncline', 'prototype': True},
    {'domain': 'biology', 'debate': 'darwin_vs_lamarck_evolution'},
    {'domain': 'physics', 'debate': 'wave_vs_particle_light'},
    {'domain': 'chemistry', 'debate': 'atomic_vs_continuous_matter'},
    {'domain': 'cosmology', 'debate': 'big_bang_vs_steady_state'},
    {'domain': 'medicine', 'debate': 'germ_vs_miasma_theory'},
    {'domain': 'astronomy', 'debate': 'heliocentric_vs_geocentric'},
    {'domain': 'genetics', 'debate': 'mendelian_vs_blending_inheritance'}
]
```

**Statistical Validation Integration**:
The manual prototype establishes quality benchmarks that DSPy automation must maintain:
- **Evidence Density**: ≥ 3 primary sources per SNO (demonstrated in manual construction)
- **Reasoning Complexity**: ≥ 5 interconnected claims per reasoning graph
- **Hypothesis Precision**: Semantic clarity score ≥ 0.9 for automated validation
- **Ground Truth Alignment**: Verifiable modern consensus for objective synthesis evaluation

This template ensures that automated generation maintains the scientific rigor demonstrated in the manual prototype while scaling to the sample sizes required for statistical significance in CNS 2.0 validation.
